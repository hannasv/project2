{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part d: regression on 1Dim ising modellusing a multilayer perceptron (neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "np.random.seed(12)\n",
    "\n",
    "import warnings\n",
    "#Comment this to turn on warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_comparison import model_comparison\n",
    "from resample import resample\n",
    "import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn\n",
    "\n",
    "\n",
    "from ann import NeuralNetMLP\n",
    "from utils import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nComparing to project 1 - x = states, z = energies... \\nCurrently no y since we are in one dimension. \\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### define Ising model aprams\n",
    "# system size\n",
    "L=40\n",
    "\n",
    "# create 10000 random Ising states\n",
    "states=np.random.choice([-1, 1], size=(10000,L))\n",
    "\n",
    "def ising_energies(states,L):\n",
    "    \"\"\"\n",
    "    This function calculates the energies of the states in the nn Ising Hamiltonian\n",
    "    \"\"\"\n",
    "    J=np.zeros((L,L),)\n",
    "    for i in range(L):\n",
    "        J[i,(i+1)%L]-=1.0\n",
    "    # compute energies\n",
    "    E = np.einsum('...i,ij,...j->...',states,J,states)\n",
    "\n",
    "    return E\n",
    "# calculate Ising energies\n",
    "energies=ising_energies(states,L)\n",
    "\n",
    "\"\"\"\n",
    "Comparing to project 1 - x = states, z = energies... \n",
    "Currently no y since we are in one dimension. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape Ising states into RL samples: S_iS_j --> X_p\n",
    "states=np.einsum('...i,...j->...ij', states, states)\n",
    "shape=states.shape\n",
    "states=states.reshape((shape[0],shape[1]*shape[2])) \n",
    "# build final data set\n",
    "Data=[states,energies]\n",
    "\n",
    "# define number of samples\n",
    "n_samples=600\n",
    "# define train and test data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=Data[0]\n",
    "Y=Data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 1600), (8000,), (2000, 1600), (2000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, split_size=0.2)\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (100, 1600)\n",
      "W_h:(1600, 30)\n",
      "b:h [[ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]\n",
      " [ 0.0001]]\n",
      "[[  1.41494948  15.00934761 -12.46468113 ..., -10.70416905  -0.27020254\n",
      "    6.50230719]\n",
      " [ -3.16666705  18.38263694  12.28496091 ..., -12.05060283 -19.25496253\n",
      "  -10.86523851]\n",
      " [ -6.23625128   2.74997505   5.356832   ...,   7.8696442  -23.97499602\n",
      "   -6.05602347]\n",
      " ..., \n",
      " [ -9.95935563  -7.2811398    0.31993054 ...,  -9.46665853  -5.15594953\n",
      "   -3.64602459]\n",
      " [-22.42574126  15.24270092   2.02813233 ...,  32.55315136  18.16674169\n",
      "  -23.26165846]\n",
      " [ -2.5019229   17.34619567  -4.17297809 ...,  38.58621717  19.32244671\n",
      "  -26.51309218]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,30) (30,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6271127fa580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                    eta = 0.001)\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m# returns a list of the mean mse score for different epochs or batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid_preform\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hanna/project2/ann.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;31m# Includes forward + backward prop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minibatch_sgd\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;31m# Evaluation after each epoch during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hanna/project2/ann.py\u001b[0m in \u001b[0;36m_minibatch_sgd\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;31m# Forwardpropagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             Z_hidden, A_hidden, Z_out, A_out = self._forwardprop(\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             )\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hanna/project2/ann.py\u001b[0m in \u001b[0;36m_forwardprop\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b:h \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mZ_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0mA_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,30) (30,1) "
     ]
    }
   ],
   "source": [
    "# Experimental setup\n",
    "\"\"\" To similar for neural network \n",
    "models = {\n",
    "    \"ols\": algorithms.OLS,\n",
    "    #\"ols\": LinearRegression,\n",
    "    'ridge': algorithms.Ridge, \n",
    "    \"lasso\": algorithms.Lasso\n",
    "}\n",
    "param_grid = {\n",
    "    'ols': [0],\n",
    "    'ridge': ,  \n",
    "    'lasso': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100, 10**3, 10**4, 10**5]\n",
    "}\n",
    "\n",
    "# Choosing the same splitsize as the notebook in order to compare. \n",
    "results, z_pred_best, coeffs = model_comparison(\n",
    "    models, param_grid, X, Y, split_size=0.33333333\n",
    "    )\n",
    "\"\"\"\n",
    "metric = []\n",
    "\n",
    "# eta > 0.001 causes divergense. \n",
    "\n",
    "lmdas = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "\n",
    "ann = NeuralNetMLP(l2 = 0.1, \n",
    "                   batch_size=100, \n",
    "                   epochs=10, \n",
    "                   n_hidden=30,\n",
    "                   #h_layers=[30,30,30],\n",
    "                   eta = 0.001)\n",
    "\n",
    "ann.fit(X_train, y_train, X_valid, y_valid)\n",
    "# returns a list of the mean mse score for different epochs or batches\n",
    "metric.append(np.mean(ann.eval_[\"valid_preform\"]))\n",
    "print(np.mean(ann.eval_[\"valid_preform\"]))\n",
    "# returns mse for each batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparing to scikitlearn MLPregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(max_iter=100)\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
