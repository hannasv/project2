{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "np.random.seed(12)\n",
    "\n",
    "import warnings\n",
    "#Comment this to turn on warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_comparison import model_comparison\n",
    "from resample import resample\n",
    "import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the coupeling coefficient J. \n",
    "\n",
    "Want to predict the energy with E = X*J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nComparing to project 1 - x = states, z = energies... \\nCurrently no y since we are in one dimension. \\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### define Ising model aprams\n",
    "# system size\n",
    "L=40\n",
    "\n",
    "# create 10000 random Ising states\n",
    "states=np.random.choice([-1, 1], size=(10000,L))\n",
    "\n",
    "def ising_energies(states,L):\n",
    "    \"\"\"\n",
    "    This function calculates the energies of the states in the nn Ising Hamiltonian\n",
    "    \"\"\"\n",
    "    J=np.zeros((L,L),)\n",
    "    for i in range(L):\n",
    "        J[i,(i+1)%L]-=1.0\n",
    "    # compute energies\n",
    "    E = np.einsum('...i,ij,...j->...',states,J,states)\n",
    "\n",
    "    return E\n",
    "# calculate Ising energies\n",
    "energies=ising_energies(states,L)\n",
    "\n",
    "\"\"\"\n",
    "Comparing to project 1 - x = states, z = energies... \n",
    "Currently no y since we are in one dimension. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.min(), states.max() #spin down, spin up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-20.0, 20.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energies.min(), energies.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape Ising states into RL samples: S_iS_j --> X_p\n",
    "states=np.einsum('...i,...j->...ij', states, states)\n",
    "shape=states.shape\n",
    "states=states.reshape((shape[0],shape[1]*shape[2])) \n",
    "# build final data set\n",
    "Data=[states,energies]\n",
    "\n",
    "# define number of samples\n",
    "n_samples=600\n",
    "# define train and test data sets\n",
    "X=Data[0][:n_samples]\n",
    "Y=Data[1][:n_samples] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same amount of data as imput in order to compare with the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression analysis - part b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-accd9462aa4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Choosing the same splitsize as the notebook in order to compare.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m results, z_pred_best, coeffs = model_comparison(\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33333333\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Experimental setup\n",
    "models = {\n",
    "    \"ols\": algorithms.OLS,\n",
    "    #\"ols\": LinearRegression,\n",
    "    'ridge': algorithms.Ridge, \n",
    "    \"lasso\": algorithms.Lasso\n",
    "}\n",
    "param_grid = {\n",
    "    'ols': [0],\n",
    "    'ridge': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100, 10**3, 10**4, 10**5],  \n",
    "    'lasso': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100, 10**3, 10**4, 10**5]\n",
    "}\n",
    "\n",
    "# Choosing the same splitsize as the notebook in order to compare. \n",
    "results, z_pred_best, coeffs = model_comparison(\n",
    "    models, param_grid, X, Y, split_size=0.33333333\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"r2_test\"][\"lasso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"r2_test\"][\"ols\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate figure\n",
    "\n",
    "# MSE\n",
    "plt.figure(1, figsize = (13,7))\n",
    "plt.subplot(1,2,1)\n",
    "xlogr = np.log10(param_grid['ridge'])  # log x-axis\n",
    "plt.plot(xlogr, (results[\"mse_train\"][\"ols\"]*np.ones(len(xlogr))).T, 'r', label='OLS (train)', linewidth=3.0) \n",
    "plt.plot(xlogr, (results[\"mse_test\"][\"ols\"]*np.ones(len(xlogr))).T, 'r--', label='OLS (test)',  linewidth=3.0) \n",
    "plt.plot(xlogr, np.asarray(results[\"mse_train\"][\"ridge\"]).T, 'b', label='Ridge (train)', linewidth=3.0) \n",
    "plt.plot(xlogr, np.asarray(results[\"mse_test\"][\"ridge\"]).T, 'b--', label='Ridge (test)', linewidth=3.0) \n",
    "plt.plot(xlogr, np.asarray(results[\"mse_train\"][\"lasso\"]).T, 'g', label='LASSO (train)', linewidth=3.0) \n",
    "plt.plot(xlogr, np.asarray(results[\"mse_test\"][\"lasso\"]).T, 'g--', label='LASSO (test)', linewidth=3.0) \n",
    "ax = plt.gca()\n",
    "plt.xticks(np.asarray(xlogr))\n",
    "ax.set_xticklabels(param_grid['ridge'])\n",
    "plt.xlabel('λ', fontsize=14)\n",
    "plt.ylabel('MSE', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "# R-squared\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(xlogr, (results[\"r2_train\"][\"ols\"]*np.ones(len(xlogr))).T, 'r', label='OLS (train)', linewidth=3.0) \n",
    "plt.plot(xlogr, (results[\"r2_test\"][\"ols\"]*np.ones(len(xlogr))).T, 'r--', label='OLS (test)', linewidth=3.0) \n",
    "plt.plot(xlogr, np.asarray(results[\"r2_train\"][\"ridge\"]).T, 'b', label='Ridge (train)', linewidth=3.0) \n",
    "plt.plot(xlogr, np.asarray(results[\"r2_test\"][\"ridge\"]).T, 'b--', label='Ridge (test)', linewidth=3.0) \n",
    "plt.plot(xlogr, np.asarray(results[\"r2_train\"][\"lasso\"]).T, 'g', label='LASSO (train)', linewidth=3.0) \n",
    "plt.plot(xlogr, np.asarray(results[\"r2_test\"][\"lasso\"]).T, 'g--', label='LASSO (test)', linewidth=3.0) \n",
    "ax = plt.gca()\n",
    "plt.xticks(np.asarray(xlogr))\n",
    "ax.set_xticklabels(param_grid['ridge'])\n",
    "plt.xlabel('λ', fontsize=14)\n",
    "plt.ylabel('R2', fontsize=14)\n",
    "plt.legend()\n",
    "plt.suptitle(\"Performance of OLS, Ridge and LASSO regressions\", y=1.05, fontsize=17)\n",
    "plt.savefig(\"results/figures/metric_regression_on_allData.png\", bbox_inches = \"tight\")\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same amount of trainingdata and testdata creates a almost similar plot Metha et al has the test line on 0.6 while we have it at 0.5617. Should be good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the coefficient of regression which is the coupling coefficient J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Need to get olscoeff.reshape((40,40))\n",
    "* Need to get the betas as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "J_ols = coeffs[\"ols\"][0][0].reshape((40,40))\n",
    "J_ridge = np.array(coeffs[\"ridge\"][0][1]).reshape((40,40))\n",
    "J_lasso = coeffs[\"lasso\"][0][1].reshape((40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.shape(coeffs[\"ridge\"])\n",
    "lmbda = param_grid[\"ridge\"]\n",
    "#idx_lmd = 1\n",
    "#J_ridge = coeffs[\"ridge\"][0][idx_lmd].reshape((40,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_args=dict(vmin=-1., vmax=1., cmap='seismic')\n",
    "#fig = plt.figure(figsize = (6,12))\n",
    "fig, axarr = plt.subplots(nrows=1, ncols=3) #, figsize=(15,15)\n",
    "\n",
    "axarr[0].imshow(J_ols,**cmap_args)\n",
    "axarr[0].set_title('$\\\\mathrm{OLS}$',fontsize=16)\n",
    "axarr[0].tick_params(labelsize=16)\n",
    "\n",
    "axarr[1].imshow(J_ridge,**cmap_args)\n",
    "axarr[1].set_title('$\\\\mathrm{Ridge}, \\ \\\\lambda= %.4f$' %(lmbda[1]),fontsize=16) # %(lmbda)\n",
    "axarr[1].tick_params(labelsize=16)\n",
    "\n",
    "im=axarr[2].imshow(J_lasso,**cmap_args)\n",
    "axarr[2].set_title('$\\\\mathrm{LASSO},\\ \\\\lambda=%.4f $' %(lmbda[1]) ,fontsize=16) #%(lmbda)\n",
    "axarr[2].tick_params(labelsize=16)\n",
    "\n",
    "divider = make_axes_locatable(axarr[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar=fig.colorbar(im, cax=cax)\n",
    "\n",
    "cbar.ax.set_yticklabels(np.arange(-1.0, 1.0+0.25, 0.25),fontsize=14)\n",
    "cbar.set_label('$J_{i,j}$',labelpad=-40, y=1.12,fontsize=16,rotation=0)\n",
    "fig.subplots_adjust(right=2.0)\n",
    "fig.savefig(\"./results/figures/best_lambdas_one_dim.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: all lambdavalues -- plotte tom. lmd = 1.0 dette får plass på en A4 side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmap_args=dict(vmin=-1., vmax=1., cmap='seismic')\n",
    "counter = 0\n",
    "\n",
    "fig, axarr = plt.subplots(nrows=len(lmbda[:5]), ncols=3, figsize = (6,27))\n",
    "rownr = 0\n",
    "\n",
    "lmbda = lmbda[:5]\n",
    "\n",
    "for lmd in lmbda:\n",
    "    \n",
    "    J_ols = coeffs[\"ols\"][0][0].reshape((40,40))\n",
    "    J_ridge = np.array(coeffs[\"ridge\"][0][counter]).reshape((40,40))\n",
    "    J_lasso = coeffs[\"lasso\"][0][counter].reshape((40,40))\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    axarr[rownr, 0].imshow(J_ols,**cmap_args)\n",
    "    axarr[rownr, 0].set_title('$\\\\mathrm{OLS}$',fontsize=16)\n",
    "    axarr[rownr, 0].tick_params(labelsize=16)\n",
    "\n",
    "    axarr[rownr,1].imshow(J_ridge,**cmap_args)\n",
    "    axarr[rownr,1].set_title('$\\\\mathrm{Ridge}, \\ \\\\lambda= %.4f$' %(lmd),fontsize=16) # %(lmbda)\n",
    "    axarr[rownr,1].tick_params(labelsize=16)\n",
    "\n",
    "    im=axarr[rownr,2].imshow(J_lasso,**cmap_args)\n",
    "    axarr[rownr,2].set_title('$\\\\mathrm{LASSO},\\ \\\\lambda=%.4f $' %(lmd) ,fontsize=16) #%(lmbda)\n",
    "    axarr[rownr,2].tick_params(labelsize=16)\n",
    "\n",
    "    divider = make_axes_locatable(axarr[rownr,2])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar=fig.colorbar(im, cax=cax)\n",
    "\n",
    "    cbar.ax.set_yticklabels(np.arange(-1.0, 1.0+0.25, 0.25),fontsize=14)\n",
    "    cbar.set_label('$J_{i,j}$',labelpad=-40, y=1.12,fontsize=16,rotation=0)\n",
    "    fig.subplots_adjust(right=2.0)\n",
    "    rownr+=1\n",
    "    \n",
    "fig.savefig(\"./results/figures/all_lambdas_one_dim.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bias and variance discussion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental setup\n",
    "models = {\n",
    "    \"ols\": algorithms.OLS, \n",
    "    \"ridge\": algorithms.Ridge, \n",
    "    \"lasso\": algorithms.Lasso, \n",
    "}\n",
    "\n",
    "lmd = {\n",
    "    'ols': [0],\n",
    "    'lasso': [0.001],\n",
    "    'ridge':[0.001]\n",
    "    \n",
    "}\n",
    "nboots = 100\n",
    "\n",
    "z_test, z_pred_test, bias, var, beta, mse_test, mse_train, ci_beta = resample(models, lmd, X, Y, nboots, split_size = 0.33333333)\n",
    "\n",
    "ci_beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_beta.shape # Muligens ikke så mys vits med konfidenseintervall av disse dimensjoner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var # variance dominates because we don't have so mush data???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias[\"ols\"] + var[\"ols\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias and variance summes to the mse of the ols model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
