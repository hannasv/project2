# Two types  of optimizer:
def stochastic_gradient_descent(eta, n_iter):
    pass

def standard_gradient_descent(eta, n_epochs, t0, t1):
    pass

def mini_batch_gradient_descent(eta, n_epochs, batch_size):
    pass
