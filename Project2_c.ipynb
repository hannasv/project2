{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 : two dimentional Ising model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as skms\n",
    "import sklearn.linear_model as skl\n",
    "import sklearn.metrics as skm\n",
    "import tqdm\n",
    "import copy\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "import algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dir = os.path.join(os.getcwd(), \"files\")\n",
    "filenames = glob.glob(os.path.join(file_dir, 'Ising2D*'))\n",
    "label_filename = list(filter(lambda x: \"label\" in x, filenames))[0]\n",
    "dat_filename = list(filter(lambda x: \"label\" not in x, filenames))[0]\n",
    "\n",
    "# Read in the labels\n",
    "with open(label_filename, \"rb\") as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "# Read in the corresponding configurations\n",
    "with open(dat_filename, \"rb\") as f:\n",
    "    data = np.unpackbits(pickle.load(f)).reshape(-1, 1600).astype(\"int\")\n",
    "\n",
    "# Set spin-down to -1\n",
    "data[data == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "def read_t(t,root=\"./files/\"):\n",
    "    data = pickle.load(open(root+'Ising2DFM_reSample_L40_T=%.2f.pkl'%t,'rb'))\n",
    "    return np.unpackbits(data).astype(int).reshape(-1,1600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding T = 2.0, 2.25, 2.5 because they are the critical phase and we have a binary model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pretty sure we don't need this anymore \n",
    "t = [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.75, 3.0, 3.25, 3.5, 3.75, 4.0]\n",
    "\n",
    "ordered = []\n",
    "disordered = []\n",
    "\n",
    "for t in t:\n",
    "    if (t<2.0):\n",
    "        ordered.append(read_t(t))\n",
    "    else:\n",
    "        disordered.append(read_t(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set spin-down to minus one. \n",
    "ordered[ordered == 0] = -1\n",
    "disordered[disordered == 0] = -1\n",
    "\n",
    "# now the spin has values either plus or minus one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Labels for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "filenames = glob.glob(os.path.join(cwd, 'files*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_filename = list(filter(lambda x: \"label\" in x, filenames))[0]\n",
    "# dat_filename = list(filter(lambda x: \"label\" not in x, filenames))[0]\n",
    "\n",
    "# Read in the labels\n",
    "with open(label_filename, \"rb\") as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "# Read in the corresponding configurations\n",
    "with open(dat_filename, \"rb\") as f:\n",
    "    data = np.unpackbits(pickle.load(f)).reshape(-1, 1600).astype(\"int\")\n",
    "\n",
    "# Set spin-down to -1\n",
    "data[data == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up slices of the dataset\n",
    "ordered = slice(0, 70000)\n",
    "critical = slice(70000, 100000)\n",
    "disordered = slice(100000, 160000)\n",
    "\n",
    "X = np.concatenate((data[ordered], data[disordered])),\n",
    "Y = np.concatenate((labels[ordered], labels[disordered]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, ..., 1, 1, 1]), 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 1\n",
    "X[0][ind], Y[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "        [ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [-1, -1,  1, ...,  1, -1, -1],\n",
       "        ..., \n",
       "        [ 1,  1,  1, ...,  1,  1, -1],\n",
       "        [ 1,  1,  1, ...,  1, -1, -1],\n",
       "        [ 1,  1,  1, ...,  1, -1, -1]]),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# experimental setup:\n",
    "\n",
    "lmda = [0.001,0.01,0.1,1.0,10.]\n",
    "eta = [0.001,0.01,0.1]\n",
    "n_iter = [10,50,100]\n",
    "key = \"sigmoid\" # and ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[0], Y, split_size=0.333333, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta = 0.01\n",
    "n_iter = 50\n",
    "random_state = 1\n",
    "key = \"ols\" \n",
    "lmd=0.01\n",
    "# (self, eta, random_state, key, n_iter = 50, lmd = 0, tolerance=1e-14):\n",
    "a = algorithms.LogisticRegression(eta, random_state, key, n_iter, lmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.sum(score == y_test)/len(score)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new ols 0.99189918991899195\n",
    "\n",
    "# ridge lmd = 0.01 0.501950195019502\n",
    "# ridge lmd = 0.001 0.89378937893789379\n",
    "# ridge lmd = 0.0001 0.99099909990999102\n",
    "\n",
    "# lasso lmd = 0.1 0.99009900990099009\n",
    "# lasso lmd = 0.01 0.9924992499249925\n",
    "# lasso lmd = 0.001 0.99279927992799277\n",
    "#lasso lmd = 0.0001 0.99279927992799277\n",
    "\n",
    "# eta = 0.01, lmd = 0.00 0.99579957995799584\n",
    "# lmd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = {\"ols\": [], \"ridge\":[], \"lasso\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = [0.0001, 0.001, 0.01, 0.1]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "\n",
    "for e in eta:\n",
    "    for l in lmd:\n",
    "        a = algorithms.LogisticRegression(e, random_state, key, n_iter, l)\n",
    "        log = a.fit(X_train, y_train)\n",
    "        score = log.predict(X_test)\n",
    "        acc = np.sum(score == y_test)/len(score)\n",
    "        accuracy[key].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy[\"lasso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array(accuracy[\"lasso\"]).reshape((len(eta), len(lmd)))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array(accuracy[\"lasso\"]).reshape((len(eta), len(lmd)))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.heatmap(m, annot = True, xticklabels=lmd, yticklabels=eta)\n",
    "ax.set_title(\"Accuracy of prediction using Lasso\", fontsize = 20)\n",
    "ax.set_xlabel(\"Lambda value\", fontsize = 15)\n",
    "ax.set_ylabel(\"Eta value\", fontsize = 15)\n",
    "plt.savefig(\"./results/figures/Logisticregression_Lasso.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"ols\"\n",
    "etas = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "for e in etas:\n",
    "    a = algorithms.LogisticRegression(e, random_state, key, n_iter)\n",
    "    log = a.fit(X_train, y_train)\n",
    "    score = log.predict(X_test)\n",
    "    acc = np.sum(score == y_test)/len(score)\n",
    "    accuracy[key].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array(accuracy[key])\n",
    "print(m)\n",
    "np.array(m).reshape((4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array(accuracy[key]).reshape(1,(len(eta)))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.heatmap(m, annot = True, xticklabels=eta)\n",
    "ax.set_title(\"Logistic regression OLS\", fontsize = 20)\n",
    "ax.set_xlabel(\"Eta value\", fontsize = 15)\n",
    "ax.set_ylabel(\"Lambda value (lmd=0)\", fontsize = 15)\n",
    "plt.savefig(\"./results/figures/Logisticregression_OLS.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = [0.0001, 0.001, 0.01, 0.1]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "\n",
    "key = \"ridge\"\n",
    "\n",
    "for e in eta:\n",
    "    for l in lmd:\n",
    "        a = algorithms.LogisticRegression(e, random_state, key, n_iter, l)\n",
    "        log = a.fit(X_train, y_train)\n",
    "        score = log.predict(X_test)\n",
    "        acc = np.sum(score == y_test)/len(score)\n",
    "        accuracy[key].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array(accuracy[key]).reshape((len(eta), len(lmd)))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.heatmap(m, annot = True, xticklabels=lmd, yticklabels=eta)\n",
    "ax.set_title(\"Logistic regression Ridge\", fontsize = 20)\n",
    "ax.set_xlabel(\"Lambda value\", fontsize = 15)\n",
    "ax.set_ylabel(\"Eta value\", fontsize = 15) #\n",
    "plt.savefig(\"./results/figures/Logisticregression_Ridge.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Accuracy of one can be reffered to as a perfect classyfier.\n",
    "# OBS! Sammenlign dette med scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
