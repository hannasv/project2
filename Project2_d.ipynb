{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part d: regression on 1Dim ising modellusing a multilayer perceptron (neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "np.random.seed(12)\n",
    "\n",
    "import warnings\n",
    "#Comment this to turn on warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_comparison import model_comparison\n",
    "from resample import resample\n",
    "import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn\n",
    "\n",
    "\n",
    "from ann import NeuralNetMLP\n",
    "from utils import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nComparing to project 1 - x = states, z = energies... \\nCurrently no y since we are in one dimension. \\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### define Ising model aprams\n",
    "# system size\n",
    "L=40\n",
    "\n",
    "# create 10000 random Ising states\n",
    "states=np.random.choice([-1, 1], size=(10000,L))\n",
    "\n",
    "def ising_energies(states,L):\n",
    "    \"\"\"\n",
    "    This function calculates the energies of the states in the nn Ising Hamiltonian\n",
    "    \"\"\"\n",
    "    J=np.zeros((L,L),)\n",
    "    for i in range(L):\n",
    "        J[i,(i+1)%L]-=1.0\n",
    "    # compute energies\n",
    "    E = np.einsum('...i,ij,...j->...',states,J,states)\n",
    "\n",
    "    return E\n",
    "# calculate Ising energies\n",
    "energies=ising_energies(states,L)\n",
    "\n",
    "\"\"\"\n",
    "Comparing to project 1 - x = states, z = energies... \n",
    "Currently no y since we are in one dimension. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape Ising states into RL samples: S_iS_j --> X_p\n",
    "states=np.einsum('...i,...j->...ij', states, states)\n",
    "shape=states.shape\n",
    "states=states.reshape((shape[0],shape[1]*shape[2])) \n",
    "# build final data set\n",
    "Data=[states,energies]\n",
    "\n",
    "# define number of samples\n",
    "n_samples=600\n",
    "# define train and test data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=Data[0]\n",
    "Y=Data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 1600), (8000,), (2000, 1600), (2000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, split_size=0.2)\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1shape: (30, 1600)\n",
      "w2shape: (30, 30)\n",
      "w3shape: (30, 30)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10,1) and (30,30) not aligned: 1 (dim 1) != 30 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-34711e2edf0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                    eta = 0.0001)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# returns a list of the mean mse score for different epochs or batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hanna/project2/ann.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;31m# Includes forward + backward prop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minibatch_sgd\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;31m# Evaluation after each epoch during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hanna/project2/ann.py\u001b[0m in \u001b[0;36m_minibatch_sgd\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;31m# Backpropagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             delta_w_out, delta_b_out = self._backprop(\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             )\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hanna/project2/ann.py\u001b[0m in \u001b[0;36m_backprop\u001b[0;34m(self, y, X, A_hidden, Z_hidden, A_out, Z_out, batch_idx)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mact_derivative3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m#print(\"shape act_deriv: \" + str(act_derivative3.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0merror_hidden3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mact_derivative3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;31m#print(\"error hidden shape: \" + str(error_hidden3.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mgrad_w_h_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_hidden3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10,1) and (30,30) not aligned: 1 (dim 1) != 30 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Experimental setup\n",
    "metric = []\n",
    "\n",
    "# eta > 0.001 causes divergense. \n",
    "\n",
    "lmdas = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "\n",
    "ann = NeuralNetMLP(l2 = 0.01, \n",
    "                   batch_size=10, \n",
    "                   epochs=50, \n",
    "                   n_hidden=30,\n",
    "                   #h_layers=[30,30,30],\n",
    "                   eta = 0.0001)\n",
    "\n",
    "ann.fit(X_train, y_train, X_valid, y_valid)\n",
    "ann.predict(X_valid)\n",
    "# returns a list of the mean mse score for different epochs or batches\n",
    "metric.append(np.mean(ann.eval_[\"valid_preform\"]))\n",
    "print(np.mean(ann.eval_[\"valid_preform\"]))\n",
    "# returns mse for each batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparing to scikitlearn MLPregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(max_iter=100)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_valid)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
