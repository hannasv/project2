{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part d: regression on 1Dim ising modellusing a multilayer perceptron (neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "np.random.seed(12)\n",
    "\n",
    "import warnings\n",
    "#Comment this to turn on warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_comparison import model_comparison\n",
    "from resample import resample\n",
    "import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from annCopy import NeuralNetMLP\n",
    "from ann import NeuralNetMLPdeep\n",
    "from utils import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nComparing to project 1 - x = states, z = energies... \\nCurrently no y since we are in one dimension. \\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### define Ising model aprams\n",
    "# system size\n",
    "L=40\n",
    "\n",
    "# create 10000 random Ising states\n",
    "states=np.random.choice([-1, 1], size=(10000,L))\n",
    "\n",
    "def ising_energies(states,L):\n",
    "    \"\"\"\n",
    "    This function calculates the energies of the states in the nn Ising Hamiltonian\n",
    "    \"\"\"\n",
    "    J=np.zeros((L,L),)\n",
    "    for i in range(L):\n",
    "        J[i,(i+1)%L]-=1.0\n",
    "    # compute energies\n",
    "    E = np.einsum('...i,ij,...j->...',states,J,states)\n",
    "\n",
    "    return E\n",
    "# calculate Ising energies\n",
    "energies=ising_energies(states,L)\n",
    "\n",
    "\"\"\"\n",
    "Comparing to project 1 - x = states, z = energies... \n",
    "Currently no y since we are in one dimension. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape Ising states into RL samples: S_iS_j --> X_p\n",
    "states=np.einsum('...i,...j->...ij', states, states)\n",
    "shape=states.shape\n",
    "states=states.reshape((shape[0],shape[1]*shape[2])) \n",
    "# build final data set\n",
    "Data=[states,energies]\n",
    "\n",
    "# define number of samples\n",
    "n_samples=600\n",
    "# define train and test data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=Data[0]\n",
    "Y=Data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 1600), (5000,), (5000, 1600), (5000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, split_size=0.5)\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nann = NeuralNetMLPdeep(l2 = 0.0001, \\n                   batch_size=10, \\n                   epochs=50, \\n                   n_hidden=30,\\n                   eta = 0.01,\\n                    tpe = \"regression\")\\n\\nann.fit(X_train, y_train, X_valid, y_valid)\\nann.predict(X_valid)\\n# returns a list of the mean mse score for different epochs or batches\\nmetric.append(ann.eval_[\"valid_preform\"])\\nprint(\" for lmd \"+str(l) + \" and eta: \" + str(e) + \"   performance is \" + str(np.mean(ann.eval_[\"valid_preform\"])))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ann = NeuralNetMLPdeep(l2 = 0.0001, \n",
    "                   batch_size=10, \n",
    "                   epochs=50, \n",
    "                   n_hidden=30,\n",
    "                   eta = 0.01,\n",
    "                    tpe = \"regression\")\n",
    "\n",
    "ann.fit(X_train, y_train, X_valid, y_valid)\n",
    "ann.predict(X_valid)\n",
    "# returns a list of the mean mse score for different epochs or batches\n",
    "metric.append(ann.eval_[\"valid_preform\"])\n",
    "print(\" for lmd \"+str(l) + \" and eta: \" + str(e) + \"   performance is \" + str(np.mean(ann.eval_[\"valid_preform\"])))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two layer MLP (Neural network )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNetMLP' object has no attribute 'tde'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-56c0724bad03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                            tpe = \"logistic\")\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# returns a list of the mean mse score for different epochs or batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hanna/project2/annCopy.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_weights_and_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;31m#print(self.W_out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hanna/project2/annCopy.py\u001b[0m in \u001b[0;36minitialize_weights_and_bias\u001b[0;34m(self, X_train)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# TODO: n_output should be equal to 2 in Logistic because we have to cases 0,1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtde\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtde\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"logistic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NeuralNetMLP' object has no attribute 'tde'"
     ]
    }
   ],
   "source": [
    "# Experimental setup\n",
    "metric = []\n",
    "\n",
    "eta = [0.0001, 0.001, 0.01, 0.1]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "\n",
    "for e in eta:\n",
    "    for l in lmd:\n",
    "        ann = NeuralNetMLP(n_hidden=30, \n",
    "                           l2=0.4,\n",
    "                           epochs=100, \n",
    "                           eta=0.001, \n",
    "                           shuffle=True,\n",
    "                            batch_size=10, \n",
    "                           seed=None, \n",
    "                           alpha=0.01, \n",
    "                           activation='elu', \n",
    "                           tpe = \"logistic\")\n",
    "            \n",
    "        ann.fit(X_train, y_train, X_valid, y_valid)\n",
    "        ann.predict(X_valid)\n",
    "        # returns a list of the mean mse score for different epochs or batches\n",
    "        metric.append(ann.eval_[\"valid_preform\"])\n",
    "        print(\" for lmd \"+str(l) + \" and eta: \" + str(e) + \"   performance is \" + str(np.mean(ann.eval_[\"valid_preform\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av = np.average(metric, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = np.array(av).reshape((len(eta), len(lmd)))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.heatmap(m, annot = True, xticklabels=lmd, yticklabels=eta)\n",
    "ax.set_title(\"Regression using sigmoid function\", fontsize = 20)\n",
    "ax.set_xlabel(\"Lambda value\", fontsize = 15)\n",
    "ax.set_ylabel(\"Eta value\", fontsize = 15) #\n",
    "plt.savefig(\"./results/figures/regression_ridge_nn_sigmoid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental setup\n",
    "metric = []\n",
    "\n",
    "eta = [0.0001, 0.001, 0.01, 0.1]\n",
    "lmd = [0.0001, 0.001, 0.01, 0.1, 1.0, 10]\n",
    "\n",
    "for e in eta:\n",
    "    for l in lmd:\n",
    "        ann = NeuralNetMLP(l2 = l, \n",
    "                           batch_size=10, \n",
    "                           epochs=100, \n",
    "                           n_hidden=30,\n",
    "                           eta = e,\n",
    "                           tpe = \"regression\")\n",
    "\n",
    "        ann.fit(X_train, y_train, X_valid, y_valid)\n",
    "        ann.predict(X_valid)\n",
    "        # returns a list of the mean mse score for different epochs or batches\n",
    "        metric.append(ann.eval_[\"valid_preform\"])\n",
    "        print(\" for lmd \"+str(l) + \" and eta: \" + str(e) + \"   performance is \" + str(np.mean(ann.eval_[\"valid_preform\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparing to scikitlearn MLPregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(30, ), activation = 'logistic', solver = \"sgd\", alpha = 0.0001, batch_size =10, learning_rate_init=0.01)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_valid)\n",
    "\n",
    "np.sum(np.square(y_pred - y_valid))/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
